{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhNgxlKFLSmgwPxj+eKgAO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghulchandramouli/GAN_series/blob/main/CGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "sFm2aMe5LTdS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=10, image_channel=1, hidden_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        self.gen = nn.Sequential(\n",
        "            self._generator_block(input_dim, hidden_dim * 4),\n",
        "            self._generator_block(\n",
        "                hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1\n",
        "            ),\n",
        "            self._generator_block(hidden_dim * 2, hidden_dim),\n",
        "            self._generator_block(\n",
        "                hidden_dim, image_channel, kernel_size=4, final_layer=True\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    def _generator_block(\n",
        "        self,\n",
        "        input_channels,\n",
        "        output_channels,\n",
        "        kernel_size=3,\n",
        "        stride=2,\n",
        "        final_layer=False,\n",
        "    ):\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(\n",
        "                    input_channels, output_channels, kernel_size, stride\n",
        "                ),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.ConvTranspose2d(\n",
        "                    input_channels, output_channels, kernel_size, stride\n",
        "                ),\n",
        "                nn.Tanh(),\n",
        "            )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
        "        return self.gen(x)\n",
        "\n",
        "\n",
        "def create_noise_vector(n_samples, input_dim, device=\"cpu\"):\n",
        "    return torch.randn(n_samples, input_dim, device=device)"
      ],
      "metadata": {
        "id": "ZsZcuns5LUtm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_channel=1, hidden_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self._discriminator_block(image_channel, hidden_dim),\n",
        "            self._discriminator_block(hidden_dim, hidden_dim * 2),\n",
        "            self._discriminator_block(hidden_dim * 2, 1, final_layer=True),\n",
        "        )\n",
        "\n",
        "    def _discriminator_block(\n",
        "        self,\n",
        "        input_channels,\n",
        "        output_channels,\n",
        "        kernel_size=4,\n",
        "        stride=2,\n",
        "        final_layer=False,\n",
        "    ):\n",
        "\n",
        "        if not final_layer:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "                nn.BatchNorm2d(output_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
        "            )\n",
        "\n",
        "    def forward(self, image):\n",
        "        disc_pred = self.disc(image)\n",
        "        return disc_pred.view(len(disc_pred), -1)"
      ],
      "metadata": {
        "id": "CKbXjUj1LYEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}